{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conselhos para aplicar aprendizado de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Obter mais exemplos de treinamento:** Mais dados podem ajudar o modelo a aprender melhor as características do problema, mas isso nem sempre é garantido.\n",
    "\n",
    "2. **Reduzir o número de características:** Às vezes, um modelo pode ter muitas características desnecessárias ou redundantes que podem estar causando ruído nos dados, portanto, simplificar o modelo pode ser benéfico.\n",
    "\n",
    "3. **Adicionar mais características:** Introduzir novas características relevantes pode melhorar a capacidade do modelo de fazer previsões precisas.\n",
    "\n",
    "4. **Adicionar características polinomiais:** Transformar características existentes em suas formas polinomiais (como $x_1^2$, $x_2^2$, $x_1x_2$, etc.) pode ajudar a captar relações não lineares nos dados.\n",
    "\n",
    "5. **Ajustar o parâmetro de regularização $ \\lambda $:** Modificar o valor de $ \\lambda $ pode ajudar a balancear a complexidade do modelo e o sobreajuste. Um $ \\lambda $ muito alto pode levar a um modelo muito simplista, enquanto um $ \\lambda $ muito baixo pode causar sobreajuste.\n",
    "\n",
    "A eficácia de cada uma dessas abordagens pode variar de acordo com o contexto específico do problema. Por isso, a implementação de diagnósticos ou testes pode ser extremamente útil para determinar qual dessas estratégias pode ser mais eficaz para melhorar o desempenho de seu modelo. Esses diagnósticos podem incluir:\n",
    "\n",
    "- **Curvas de aprendizado:** Para avaliar se mais dados melhorarão o modelo.\n",
    "- **Análise de erro:** Para entender quais tipos de erro o modelo está cometendo e como características adicionais podem ajudar.\n",
    "- **Validação cruzada:** Para testar a robustez do modelo com diferentes subconjuntos de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando um modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao desenvolver modelos de aprendizado de máquina, avaliar seu desempenho de forma sistemática é crucial para entender como melhorá-los. Vamos explorar como você pode avaliar e melhorar a performance de um modelo usando o exemplo de previsão de preços de imóveis.\n",
    "\n",
    "### Contexto do Problema\n",
    "Suponha que você tenha implementado uma regressão linear regularizada para prever preços de imóveis com base no tamanho do imóvel (x). Você decidiu usar um modelo polinomial de quarta ordem, o que significa que o modelo inclui $ x, x^2, x^3, $ e $ x^4 $ como características. Embora este modelo se ajuste bem aos dados de treinamento, você suspeita que ele pode não generalizar bem para novos exemplos fora do conjunto de treinamento, devido à sua complexidade e ao comportamento oscilante da curva de previsão.\n",
    "\n",
    "### Avaliação do Modelo\n",
    "Avaliar um modelo quando ele se baseia em apenas uma característica é relativamente simples, pois você pode visualizar a relação entre x e y através de um gráfico. No entanto, quando o modelo inclui múltiplas características, como tamanho, número de quartos, andares e idade do imóvel, visualizar a função de previsão $ f $ torna-se complexo devido à multidimensionalidade.\n",
    "\n",
    "#### Divisão de Dados\n",
    "Para avaliar o modelo de forma mais sistemática, especialmente quando não é possível visualizar diretamente a função $ f $, uma abordagem comum é dividir seu conjunto de dados em dois subconjuntos: um conjunto de treinamento e um conjunto de teste. Por exemplo, você pode dividir seu conjunto de dados em 70% para treinamento e 30% para testes. Você treinará seu modelo nos 70% e avaliará seu desempenho nos 30% restantes.\n",
    "\n",
    "#### Cálculo do Erro\n",
    "Para medir o desempenho, você pode usar a função de custo quadrático médio. Para o conjunto de treinamento, você minimiza a função de custo:\n",
    "\n",
    "$$ J(w, b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f(x^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^n w_j^2 $$\n",
    "\n",
    "onde $ m $ é o número de exemplos de treinamento, $ \\lambda $ é o parâmetro de regularização, e $ w_j $ são os pesos do modelo. Para o conjunto de teste, o erro de teste $ J_{\\text{test}} $ é calculado sem o termo de regularização:\n",
    "\n",
    "$$ J_{\\text{test}}(w, b) = \\frac{1}{2m_{\\text{test}}} \\sum_{i=1}^{m_{\\text{test}}} (f(x_{\\text{test}}^{(i)}) - y_{\\text{test}}^{(i)})^2 $$\n",
    "\n",
    "#### Interpretação dos Resultados\n",
    "Se o erro de treinamento $ J_{\\text{train}} $ é baixo, mas o erro de teste $ J_{\\text{test}} $ é alto, isso indica que o modelo está sobreajustado (overfitting) aos dados de treinamento e não generaliza bem para novos dados. Este diagnóstico sugere que você pode precisar simplificar o modelo ou adicionar mais dados de treinamento para ajudar o modelo a generalizar melhor.\n",
    "\n",
    "### Próximos Passos\n",
    "Dependendo dos resultados da avaliação, você pode optar por ajustar o número de características, modificar o grau do polinômio, ajustar o parâmetro de regularização $ \\lambda $, ou experimentar diferentes métodos de regularização. Outros diagnósticos, como análise de resíduos ou validação cruzada, também podem oferecer insights sobre como melhorar o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de modelo e treinamento/validação cruzada/conjuntos de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A avaliação e a escolha de modelos em projetos de machine learning são passos críticos para garantir que os modelos desenvolvidos possam generalizar bem para dados não vistos durante o treinamento. Para ilustrar esse processo de forma mais sistemática, vamos explorar como utilizar conjuntos de dados de treinamento, validação cruzada (cross-validation) e teste para escolher e avaliar um modelo de machine learning.\n",
    "\n",
    "### Configuração do Problema\n",
    "Suponha que você está ajustando um modelo para prever preços de imóveis usando regressão polinomial. Você experimenta com polinômios de diferentes ordens, variando de um modelo linear (primeira ordem) até um polinômio de décima ordem.\n",
    "\n",
    "### Divisão dos Dados\n",
    "Para avaliar e selecionar o modelo mais adequado, você divide seus dados em três subconjuntos:\n",
    "- **Conjunto de Treinamento:** Usado para ajustar os parâmetros do modelo.\n",
    "- **Conjunto de Validação Cruzada:** Usado para selecionar o modelo com melhor desempenho entre várias opções.\n",
    "- **Conjunto de Teste:** Usado para estimar o erro de generalização do modelo final escolhido.\n",
    "\n",
    "### Processo de Seleção e Avaliação\n",
    "1. **Treinamento de Modelos Diferentes:** Para cada grau do polinômio (de 1 a 10), ajuste um modelo no conjunto de treinamento e calcule o erro no conjunto de validação cruzada.\n",
    "2. **Seleção do Modelo:** Compare os erros de validação cruzada para todos os modelos treinados e escolha o modelo que apresenta o menor erro. Este passo é crucial porque permite identificar qual configuração do modelo equilibra melhor entre ajuste e capacidade de generalização.\n",
    "3. **Avaliação de Generalização:** Uma vez escolhido o modelo ideal usando o conjunto de validação cruzada, você finalmente avalia este modelo no conjunto de teste para estimar o erro de generalização. Este passo confirma se o modelo selecionado realmente funciona bem em dados novos e não vistos.\n",
    "\n",
    "### Considerações Importantes\n",
    "- **Erro de Treinamento vs. Erro de Validação vs. Erro de Teste:** O erro de treinamento geralmente é otimista e não reflete a capacidade do modelo de generalizar para novos dados. O erro de validação ajuda a selecionar o modelo, enquanto o erro de teste fornece uma estimativa não tendenciosa do desempenho do modelo em novos dados.\n",
    "- **Uso Correto dos Dados:** É crucial que o conjunto de teste seja usado apenas uma vez, no final do processo, para evitar vieses na seleção do modelo e garantir uma avaliação honesta da generalização do modelo.\n",
    "\n",
    "### Exemplo Prático\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Gerando dados simulados\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1) * 10\n",
    "y = 3 * x.squeeze()**2 + 2 * x.squeeze() + 1 + np.random.randn(100) * 10\n",
    "\n",
    "# Dividindo os dados\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.25, random_state=0)\n",
    "\n",
    "# Testando diferentes graus de polinômios\n",
    "validation_errors = []\n",
    "degrees = list(range(1, 11))\n",
    "\n",
    "for d in degrees:\n",
    "    poly_features = PolynomialFeatures(degree=d, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(x_train)\n",
    "    model = Ridge(alpha=1e-3)\n",
    "    model.fit(x_poly_train, y_train)\n",
    "    \n",
    "    x_poly_val = poly_features.transform(x_val)\n",
    "    y_val_predict = model.predict(x_poly_val)\n",
    "    validation_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "\n",
    "# Escolhendo o modelo com menor erro de validação\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "poly_features = PolynomialFeatures(degree=best_degree, include_bias=False)\n",
    "x_poly_train_full = poly_features.fit_transform(x_train_full)\n",
    "model_final = Ridge(alpha=1e-3)\n",
    "model_final.fit(x_poly_train_full, y_train_full)\n",
    "\n",
    "# Avaliando no conjunto de teste\n",
    "x_poly_test = poly_features.transform(x_test)\n",
    "y_test_predict = model_final.predict(x_poly_test)\n",
    "test_error = mean_squared_error(y_test, y_test_predict)\n",
    "\n",
    "print(f'Melhor grau do polinômio: {best_degree}')\n",
    "print(f'Erro de teste do modelo final: {test_error}')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor grau de polinômio: 3\n",
      "Erro de teste: 103.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=4.95665e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.19251e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=5.36373e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.39255e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Gerando dados simulados\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1) * 10\n",
    "y = 3 * x.squeeze()**2 + 2 * x.squeeze() + 1 + np.random.randn(100) * 10\n",
    "\n",
    "# Dividindo os dados\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.25, random_state=0)\n",
    "\n",
    "# Testando diferentes graus de polinômios\n",
    "validation_errors = []\n",
    "degrees = list(range(1, 11))\n",
    "\n",
    "for d in degrees:\n",
    "    poly_features = PolynomialFeatures(degree=d, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(x_train)\n",
    "    model = Ridge(alpha=1e-3)\n",
    "    model.fit(x_poly_train, y_train)\n",
    "    \n",
    "    x_poly_val = poly_features.transform(x_val)\n",
    "    y_val_predict = model.predict(x_poly_val)\n",
    "    validation_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "\n",
    "# Escolhendo o modelo com menor erro de validação\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "poly_features = PolynomialFeatures(degree=best_degree, include_bias=False)\n",
    "x_poly_train_full = poly_features.fit_transform(x_train_full)\n",
    "model_final = Ridge(alpha=1e-3)\n",
    "model_final.fit(x_poly_train_full, y_train_full)\n",
    "\n",
    "# Avaliando no conjunto de teste\n",
    "x_poly_test = poly_features.transform(x_test)\n",
    "y_test_predict = model_final.predict(x_poly_test)\n",
    "test_error = mean_squared_error(y_test, y_test_predict)\n",
    "print(f'Melhor grau de polinômio: {best_degree}')\n",
    "print(f'Erro de teste: {test_error:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnosticando viés e variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliar corretamente se um algoritmo de aprendizado de máquina está sofrendo de viés alto (bias) ou variância alta (variance) é crucial para direcionar os esforços de melhoria do modelo de forma eficaz. Essa análise ajuda a entender se o modelo está simplesmente não aprendendo os padrões nos dados (alto viés) ou se está aprendendo demais os detalhes do conjunto de treinamento a ponto de falhar em generalizar para novos dados (alta variância).\n",
    "\n",
    "### Diagnóstico de Viés Alto e Variância Alta\n",
    "\n",
    "**Viés Alto (Underfitting):**\n",
    "- O modelo não consegue capturar a relação subjacente entre os dados de entrada e saídas, resultando em erros significativos tanto no conjunto de treinamento quanto no conjunto de validação.\n",
    "- **Indicadores:**\n",
    "  - Erro de treinamento (J_train) alto.\n",
    "  - Erro de validação cruzada (J_cv) também é alto, mas próximo ao erro de treinamento.\n",
    "\n",
    "**Variância Alta (Overfitting):**\n",
    "- O modelo aprende os detalhes e o ruído do conjunto de treinamento a ponto de impactar negativamente a performance no conjunto de validação.\n",
    "- **Indicadores:**\n",
    "  - Erro de treinamento (J_train) baixo.\n",
    "  - Erro de validação cruzada (J_cv) muito mais alto que o erro de treinamento.\n",
    "\n",
    "### Estratégias para Mitigar Viés e Variância\n",
    "\n",
    "**Para Viés Alto:**\n",
    "- Adicionar mais características (features) para capturar melhor a complexidade dos dados.\n",
    "- Aumentar a complexidade do modelo (por exemplo, usando polinômios de maior grau).\n",
    "- Reduzir a regularização (diminuir λ).\n",
    "\n",
    "**Para Variância Alta:**\n",
    "- Coletar mais dados de treinamento para ajudar o modelo a generalizar melhor.\n",
    "- Reduzir a complexidade do modelo (usar polinômios de menor grau).\n",
    "- Aumentar a regularização.\n",
    "\n",
    "### Exemplo Prático\n",
    "\n",
    "Suponha que você está ajustando um modelo de regressão polinomial para prever preços de imóveis e queira decidir entre diferentes graus de complexidade do modelo, do linear até polinômios de ordem superior.\n",
    "\n",
    "1. **Divida os dados em treinamento, validação e teste.**\n",
    "2. **Treine modelos de diferentes complexidades no conjunto de treinamento.**\n",
    "3. **Avalie cada modelo no conjunto de validação.**\n",
    "4. **Selecione o modelo que apresenta o melhor equilíbrio entre viés e variância, ou seja, que minimiza o erro no conjunto de validação.**\n",
    "5. **Teste o modelo selecionado no conjunto de teste para estimar o erro de generalização.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularização e viés/variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ajuste do parâmetro de regularização, Lambda, é uma ferramenta fundamental para controlar o trade-off entre viés (bias) e variância (variance) em modelos de aprendizado de máquina, especialmente em modelos de regressão. Vamos explorar como o Lambda influencia o desempenho do modelo e como você pode selecionar um valor adequado para esse parâmetro utilizando validação cruzada.\n",
    "\n",
    "### Impacto do Lambda no Desempenho do Modelo\n",
    "\n",
    "**Lambda Alto:**\n",
    "- **Efeito:** Com um Lambda muito alto, como 10.000, a regularização domina o termo de erro do treinamento, levando à minimização dos pesos $w$. Isso pode resultar em um modelo que é praticamente constante (ou seja, $f(x) \\approx b$), mostrando alto viés e subajustando os dados.\n",
    "- **Indicador de desempenho:** Tanto o erro de treinamento ($J_{\\text{train}}$) quanto o erro de validação cruzada ($J_{\\text{cv}}$) são altos.\n",
    "\n",
    "**Lambda Baixo:**\n",
    "- **Efeito:** Com um Lambda baixo, como zero, o modelo não possui regularização, o que pode levar a um ajuste excessivo dos dados de treinamento, especialmente com modelos polinomiais de alta ordem.\n",
    "- **Indicador de desempenho:** $J_{\\text{train}}$ é baixo (bom desempenho no conjunto de treinamento), mas $J_{\\text{cv}}$ é alto (mau desempenho no conjunto de validação), indicando alta variância.\n",
    "\n",
    "**Lambda Ótimo:**\n",
    "- **Efeito:** Um valor intermediário de Lambda pode proporcionar o equilíbrio certo, controlando a magnitude dos pesos sem comprometer a capacidade do modelo de ajustar bem os dados.\n",
    "- **Indicador de desempenho:** Ambos $J_{\\text{train}}$ e $J_{\\text{cv}}$ são relativamente baixos, indicando um bom ajuste geral que generaliza bem para novos dados.\n",
    "\n",
    "### Escolhendo o Valor de Lambda Usando Validação Cruzada\n",
    "\n",
    "A escolha do valor ideal de Lambda é crítica para o desempenho do seu modelo. Aqui está como você pode usar a validação cruzada para identificar o melhor Lambda:\n",
    "\n",
    "1. **Definição de uma Gama de Valores de Lambda:**\n",
    "   - Comece definindo uma lista de possíveis valores de Lambda para testar. Essa lista pode incluir valores muito pequenos, aumentando progressivamente até valores muito grandes.\n",
    "\n",
    "2. **Treinamento com Diferentes Lambdas:**\n",
    "   - Para cada valor de Lambda na lista, treine seu modelo no conjunto de treinamento e calcule $J_{\\text{train}}$.\n",
    "   - Use os parâmetros aprendidos para avaliar o modelo no conjunto de validação cruzada e calcular $J_{\\text{cv}}$.\n",
    "\n",
    "3. **Avaliação dos Resultados:**\n",
    "   - Plote os resultados de $J_{\\text{train}}$ e $J_{\\text{cv}}$ em função dos valores de Lambda.\n",
    "   - $J_{\\text{train}}$ geralmente aumenta com valores mais altos de Lambda, refletindo o aumento do viés.\n",
    "   - $J_{\\text{cv}}$ geralmente tem um comportamento de \"U\", diminuindo até um ponto ótimo antes de começar a aumentar novamente à medida que o modelo começa a subajustar.\n",
    "\n",
    "4. **Escolha do Lambda Ótimo:**\n",
    "   - O Lambda ideal é geralmente o ponto onde $J_{\\text{cv}}$ é mínimo, indicando que o modelo tem um bom equilíbrio entre viés e variância e é capaz de generalizar bem a partir dos dados de treinamento.\n",
    "\n",
    "5. **Validação Final:**\n",
    "   - Uma vez escolhido o melhor Lambda usando o conjunto de validação cruzada, avalie o desempenho do modelo usando o conjunto de teste para estimar o erro de generalização.\n",
    "\n",
    "### Importância da Regularização\n",
    "\n",
    "A regularização é uma técnica poderosa para prevenir o sobreajuste, especialmente em problemas onde o número de parâmetros é grande em relação ao número de exemplos de treinamento. Ao penalizar os pesos do modelo, a regularização ajuda a manter a simplicidade do modelo, promovendo assim uma melhor generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estabelecendo um nível básico de desempenho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática de desenvolvimento de sistemas como o de reconhecimento de fala, é fundamental medir corretamente o desempenho do algoritmo para entender se ele sofre mais de viés (bias) ou variância (variance). Essa análise pode ser complexa, especialmente em aplicações como reconhecimento de fala, onde até mesmo o desempenho humano pode não ser perfeito devido à qualidade variável das gravações.\n",
    "\n",
    "### Exemplo Prático: Reconhecimento de Fala\n",
    "\n",
    "Imagine que você desenvolveu um sistema de reconhecimento de fala e após treinamento e validação, obteve os seguintes resultados:\n",
    "- **Erro de Treinamento (J_train):** 10.8%\n",
    "- **Erro de Validação Cruzada (J_cv):** 14.8%\n",
    "- **Desempenho Humano (Baseline):** 10.6%\n",
    "\n",
    "Inicialmente, um erro de treinamento de 10.8% pode parecer alto, mas é essencial compará-lo com o desempenho humano. Se o desempenho humano está em 10.6%, isso indica que as expectativas para o algoritmo devem ser ajustadas considerando as limitações intrínsecas aos dados (por exemplo, áudio ruim ou ambíguo).\n",
    "\n",
    "### Análise de Viés e Variância\n",
    "\n",
    "1. **Comparação com Desempenho Humano:**\n",
    "   - Se o erro de treinamento está apenas ligeiramente acima do desempenho humano (10.8% vs. 10.6%), isso sugere que o algoritmo já está alcançando um limite próximo do possível com os dados atuais.\n",
    "   - O pequeno aumento no erro de treinamento (0.2% maior que o humano) indica um baixo viés, sugerindo que o algoritmo não está subajustando os dados significativamente.\n",
    "\n",
    "2. **Análise de Variância:**\n",
    "   - A diferença entre o erro de treinamento e o erro de validação cruzada (10.8% vs. 14.8%) é mais substancial (4%).\n",
    "   - Este aumento no erro de validação cruzada em relação ao erro de treinamento indica uma alta variância, sugerindo que o algoritmo pode estar sobreajustando os dados de treinamento e, portanto, não generalizando bem para novos dados não vistos.\n",
    "\n",
    "### Estratégias de Ajuste\n",
    "\n",
    "Para ajustar um algoritmo com alta variância:\n",
    "- **Coleta de Mais Dados:** Mais dados podem ajudar o modelo a aprender padrões mais generalizáveis e não apenas peculiaridades dos dados de treinamento.\n",
    "- **Simplificação do Modelo:** Reduzir a complexidade do modelo pode ajudar a diminuir o sobreajuste. Isso pode incluir a redução do número de parâmetros ou a modificação da arquitetura do modelo.\n",
    "- **Aumento da Regularização:** Ajustar o parâmetro de regularização Lambda pode ajudar a controlar o sobreajuste, penalizando os pesos do modelo mais fortemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curvas de aprendizagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As curvas de aprendizado são representações gráficas que mostram como o desempenho de um modelo de aprendizado de máquina muda à medida que a quantidade de dados de treinamento aumenta. Elas são particularmente úteis para diagnosticar se um modelo está sofrendo de superajuste (alta variância) ou subajuste (alto viés).\n",
    "\n",
    "### Entendendo as Curvas de Aprendizado\n",
    "\n",
    "Vamos detalhar os componentes e comportamentos das curvas de aprendizado usando uma função polinomial de segundo grau (quadrática) como exemplo:\n",
    "\n",
    "1. **Erro de Treinamento (J_train)**: Esta curva geralmente começa muito baixa quando o conjunto de treinamento é pequeno porque o modelo pode facilmente ajustar-se a um pequeno número de pontos. No entanto, à medida que mais pontos são adicionados, o modelo encontra cada vez mais dificuldades para ajustar todos os pontos perfeitamente, levando a um aumento no erro de treinamento.\n",
    "\n",
    "2. **Erro de Validação Cruzada (J_cv)**: Ao contrário do erro de treinamento, o erro de validação cruzada começa alto quando o conjunto de dados é pequeno porque o modelo não aprendeu o suficiente para generalizar bem. À medida que mais dados são adicionados, o modelo começa a generalizar melhor, e assim, o erro de validação cruzada diminui.\n",
    "\n",
    "### Alto Viés vs. Alta Variância\n",
    "\n",
    "- **Alto Viés (Subajuste)**:\n",
    "  - Tanto $ J_{\\text{train}} $ quanto $ J_{\\text{cv}} $ serão altos, e eles convergirão para uma taxa de erro alta à medida que mais dados forem adicionados. O modelo é muito simples e falha em capturar tendências subjacentes nos dados, apresentando desempenho ruim tanto no conjunto de treinamento quanto no de validação.\n",
    "  - **Característica Chave**: Os erros convergem e se estabilizam, indicando que adicionar mais dados não melhorará significativamente o desempenho.\n",
    "\n",
    "- **Alta Variância (Superajuste)**:\n",
    "  - $ J_{\\text{train}} $ é baixo, indicando bom desempenho no conjunto de treinamento, mas $ J_{\\text{cv}} $ é significativamente maior, mostrando uma pobre generalização para novos dados.\n",
    "  - **Característica Chave**: Existe uma grande lacuna entre os erros de treinamento e validação. Mais dados de treinamento podem ajudar a reduzir o superajuste, pois o modelo é forçado a generalizar melhor.\n",
    "\n",
    "### Implicações Práticas\n",
    "\n",
    "- **Quando Adicionar Mais Dados**:\n",
    "  - Se a curva de aprendizado indica alta variância, adicionar mais dados de treinamento pode ajudar o modelo a generalizar melhor, reduzindo $ J_{\\text{cv}} $.\n",
    "  - Se o modelo mostra alto viés, adicionar dados sozinho provavelmente não ajudará. Em vez disso, considere aumentar a complexidade do modelo ou reduzir a regularização.\n",
    "\n",
    "- **Ajustando a Complexidade do Modelo**:\n",
    "  - Para alto viés: Aumente a complexidade do modelo (por exemplo, passando de um modelo linear para um polinomial).\n",
    "  - Para alta variância: Simplifique o modelo ou aumente a regularização para penalizar a complexidade do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decidindo o que tentar em seguida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponha que você implementou uma regressão linear regularizada para prever preços de casas, mas seu algoritmo faz erros inaceitavelmente grandes em suas previsões. O que você tentaria a seguir?\n",
    "\n",
    "1. **Obter mais exemplos de treinamento**: Ajuda a resolver um problema de alta variância, especialmente se o algoritmo estava superajustando a um conjunto de treinamento muito pequeno.\n",
    "\n",
    "2. **Tentar um conjunto menor de características**: Reduz a flexibilidade do algoritmo de ajustar modelos muito complicados, ajudando a resolver problemas de alta variância.\n",
    "\n",
    "3. **Obter características adicionais**: Se o modelo não está conseguindo bom desempenho no conjunto de treinamento por falta de informações relevantes, adicionar mais características pode ajudar a diminuir o viés.\n",
    "\n",
    "4. **Adicionar características polinomiais**: Similar a adicionar novas características, aumenta a complexidade do modelo, ajudando a reduzir o alto viés.\n",
    "\n",
    "5. **Diminuir o parâmetro de regularização $ \\lambda $**: Faz com que o algoritmo preste menos atenção ao termo de regularização e mais ao ajuste dos dados, reduzindo o alto viés.\n",
    "\n",
    "6. **Aumentar o parâmetro de regularização $ \\lambda $**: Força o modelo a ser mais simples, o que pode ajudar a controlar a alta variância.\n",
    "\n",
    "Estas decisões são fundamentais porque, dependendo se o problema é de alto viés ou alta variância, as estratégias para melhorar o desempenho do modelo serão diferentes. Por exemplo:\n",
    "\n",
    "- Se o modelo sofre de **alta variância** (superajustamento), você pode beneficiar-se de mais dados de treinamento ou simplificar o modelo (reduzindo o número de características ou aumentando $ \\lambda $).\n",
    "- Se o modelo sofre de **alto viés** (subajustamento), pode ser útil tornar o modelo mais complexo (adicionando características ou reduzindo $ \\lambda $), ou mesmo aumentando a quantidade de características polinomiais para capturar melhor as complexidades dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viés/variância e redes neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essas técnicas visam abordar diretamente os problemas de viés e variância, que são críticos para o desempenho do algoritmo de aprendizado. Compreender esses conceitos e saber como e quando aplicar essas técnicas pode significativamente impactar a qualidade dos modelos de machine learning.\n",
    "\n",
    "Além disso, a popularidade crescente das redes neurais se deve, em parte, à sua capacidade de lidar simultaneamente com alto viés e alta variância, especialmente quando combinadas com grandes conjuntos de dados. Redes neurais grandes tendem a ter baixo viés, pois são capazes de se ajustar bem ao conjunto de treinamento. No entanto, elas podem sofrer de alta variância sem regularização adequada ou sem dados suficientes para suportar sua complexidade.\n",
    "\n",
    "O uso de redes neurais grandes, com regularização apropriada e conjuntos de dados substanciais, oferece uma abordagem promissora para alcançar um bom desempenho em diversas aplicações de aprendizado de máquina. Esse equilíbrio entre ajustar o modelo aos dados de treinamento (reduzindo o viés) e garantir que o modelo generalize bem para novos dados (controlando a variância) é crucial para o desenvolvimento de sistemas de aprendizado de máquina robustos e eficazes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop iterativo de desenvolvimento de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de desenvolvimento de um sistema de aprendizado de máquina é iterativo. Ele geralmente começa com a decisão sobre a arquitetura do sistema, escolhendo o modelo de aprendizado de máquina e decidindo quais dados usar. Depois de implementar e treinar o modelo, raramente ele funciona tão bem quanto desejado na primeira tentativa.\n",
    "\n",
    "A partir daí, recomenda-se implementar ou analisar alguns diagnósticos, como o viés e a variância do algoritmo, e realizar uma análise de erro, que veremos em vídeos futuros. Com base nos insights desses diagnósticos, você pode decidir fazer ajustes no modelo, como aumentar o tamanho da rede neural, alterar o parâmetro de regularização $ \\lambda $, adicionar mais dados ou ajustar as características.\n",
    "\n",
    "Por exemplo, na construção de um classificador de spam de e-mail, você pode começar com um modelo simples e, dependendo do desempenho inicial, optar por coletar mais dados (por exemplo, através de projetos honeypot para coletar spams) ou desenvolver características mais sofisticadas baseadas nas rotas de e-mail ou no conteúdo das mensagens. A seleção da abordagem correta muitas vezes depende de diagnosticar corretamente se o problema é de alto viés ou alta variância.\n",
    "\n",
    "Este ciclo iterativo de desenvolvimento permite que você refine continuamente o sistema até alcançar o desempenho desejado. Decidir qual caminho seguir pode acelerar significativamente o projeto em comparação com escolher direções menos promissoras. Por exemplo, se o algoritmo demonstra alto viés, focar em coletar mais dados pode não ser tão frutífero quanto melhorar a complexidade do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A análise de erro e o diagnóstico de viés e variância são duas ferramentas essenciais para melhorar o desempenho de algoritmos de aprendizado de máquina. Vamos explorar esses conceitos através de um exemplo prático na classificação de e-mails como spam.\n",
    "\n",
    "Imagine que você tem um conjunto de 500 exemplos para validação cruzada e seu algoritmo falha ao classificar 100 desses exemplos. Para entender e corrigir os erros, você realiza uma análise de erro, que consiste em revisar manualmente esses 100 exemplos para identificar padrões e características comuns nos erros. Por exemplo, se muitos e-mails mal classificados são tentativas de venda de produtos farmacêuticos, você poderia contabilizar quantos desses e-mails pertencem a essa categoria. Se encontrar 21 casos de spam farmacêutico, isso indica uma área específica para melhoria.\n",
    "\n",
    "Você também pode identificar outras categorias problemáticas, como e-mails com erros ortográficos deliberados ou informações de roteamento incomuns, e quantificar essas ocorrências. Este processo ajuda a estabelecer prioridades; por exemplo, se apenas três dos erros forem devido a erros ortográficos, isso pode sugerir que focar esforços para detectar esses erros pode não ser tão impactante.\n",
    "\n",
    "Por outro lado, a análise de viés e variância ajuda a determinar se coletar mais dados pode ser benéfico. No caso de erros frequentes relacionados a spam farmacêutico ou phishing, isso pode motivar a coleta de mais dados nesses específicos domínios ou o desenvolvimento de características específicas que ajudem o algoritmo a melhor identificar esses tipos de spam.\n",
    "\n",
    "Essas análises são particularmente úteis em problemas que são facilmente avaliáveis por humanos, como a identificação de spam. No entanto, em tarefas onde até mesmo humanos têm dificuldades, como prever cliques em anúncios, a análise de erro pode ser mais desafiadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adicionando dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, é comum o desejo de obter mais dados durante o treinamento de algoritmos de aprendizado de máquina, mas coletar dados de forma indiscriminada pode ser lento e caro. Uma estratégia mais eficiente é se concentrar em adicionar mais dados nos tipos específicos onde a análise indicou que haveria um benefício real. Por exemplo, se a análise de erro mostrou que o spam farmacêutico é um problema significativo, focar em obter mais exemplos desse tipo específico de spam pode ser mais custo-efetivo e benéfico para o desempenho do algoritmo.\n",
    "\n",
    "Uma maneira prática de fazer isso é explorar dados não rotulados já existentes. Por exemplo, se há muitos e-mails não etiquetados, pode-se pedir que os rotuladores revisem esses dados para identificar e rotular mais exemplos de spam farmacêutico. Esse esforço direcionado pode melhorar significativamente a performance do algoritmo ao aprender a reconhecer especificamente esse tipo de spam.\n",
    "\n",
    "Além de adicionar dados específicos, outra técnica importante é a augmentação de dados. Essa abordagem é amplamente utilizada, especialmente com dados de imagens e áudios, para aumentar efetivamente o conjunto de treinamento sem necessariamente coletar novos dados externos. A augmentação de dados envolve modificar um exemplo de treinamento existente para criar novos exemplos. Por exemplo, em um problema de reconhecimento óptico de caracteres (OCR), uma imagem de uma letra pode ser rotacionada, ampliada, reduzida ou ter seu contraste alterado para gerar novos exemplos de treinamento. Essas transformações ajudam o algoritmo a aprender que, apesar das distorções, o carácter ainda representa a mesma letra.\n",
    "\n",
    "Para um exemplo mais avançado, pode-se colocar uma grade sobre a imagem de uma letra e introduzir distorções aleatórias nessa grade. Isso cria uma variedade rica de representações para a mesma letra, enriquecendo o conjunto de treinamento e ajudando o algoritmo a reconhecer a letra em diversas condições."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A técnica de augmentação de dados também é aplicável no reconhecimento de voz, como em aplicações de busca por voz. Para ilustrar, considere um clipe de áudio original com alguém dizendo \"Qual é a previsão do tempo hoje?\". Uma maneira de aplicar augmentação de dados nesse áudio seria adicionar sons de fundo, como o ruído de uma multidão ou o barulho de um carro, ao áudio original. Ao combinar o clipe de voz com esses ruídos de fundo, cria-se novos exemplos de treinamento onde a voz é dita em diferentes ambientes. Isso ajuda o algoritmo a aprender a reconhecer comandos de voz em diversas situações acústicas.\n",
    "\n",
    "Além disso, pode-se alterar a qualidade do áudio para simular uma conexão ruim de telefone celular, gerando mais um exemplo de treinamento. Essas técnicas foram críticas para aumentar artificialmente o tamanho do conjunto de dados de treinamento em sistemas de reconhecimento de voz, tornando o reconhecedor de voz mais preciso.\n",
    "\n",
    "É importante que as alterações ou distorções feitas nos dados sejam representativas dos tipos de ruído ou distorções esperados no conjunto de testes. Por exemplo, no caso de reconhecimento de caracteres ópticos (OCR) em fotos, você pode criar dados sintéticos digitando textos em diferentes fontes e capturando imagens desses textos. Esses dados sintéticos podem parecer muito realistas e são úteis para treinar algoritmos de OCR para reconhecer textos em imagens variadas.\n",
    "\n",
    "A geração de dados sintéticos envolve a criação de novos exemplos a partir do zero, não apenas modificando exemplos existentes. Esse método é amplamente utilizado em tarefas de visão computacional e menos em outras aplicações, como tarefas de áudio. A criação de dados sintéticos realistas pode exigir um esforço significativo para escrever o código necessário, mas, uma vez desenvolvido, esse método pode aumentar substancialmente a quantidade de dados disponíveis para treinamento e melhorar drasticamente o desempenho do algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferência de aprendizado: usando dados de uma tarefa diferente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transferência de aprendizado é uma técnica valiosa, especialmente em aplicações onde os dados são escassos. Essa técnica permite que você utilize dados de uma tarefa diferente para ajudar em sua aplicação específica. Vejamos como isso funciona na prática, especialmente em um cenário onde deseja-se reconhecer dígitos escritos à mão de zero a nove, mas dispõe-se de poucos dados rotulados para esses dígitos.\n",
    "\n",
    "Suponha que você tenha acesso a um grande conjunto de dados contendo um milhão de imagens de mil classes diferentes, como gatos, cães, carros e pessoas. O primeiro passo é treinar uma rede neural nesse vasto conjunto de dados para que aprenda a reconhecer essas mil classes a partir de uma imagem de entrada. Durante esse processo, você obtém os parâmetros para várias camadas da rede, desde a primeira até a camada de saída.\n",
    "\n",
    "Para aplicar a transferência de aprendizado, você faz uma cópia desta rede neural, mantendo os parâmetros das primeiras camadas (por exemplo, W^1, b^1 até W^4, b^4), mas substitui a camada de saída, que originalmente tinha mil unidades, por uma nova com apenas dez unidades. Essas dez unidades correspondem aos dez dígitos (de zero a nove) que sua rede precisa reconhecer. Os parâmetros da nova camada de saída (W^5, b^5) precisam ser treinados do zero, pois as dimensões dessa camada mudaram.\n",
    "\n",
    "Existem basicamente duas opções para treinar essa nova rede neural:\n",
    "\n",
    "1. **Opção 1**: Treinar apenas os parâmetros da camada de saída. Aqui, você mantém fixos os parâmetros das primeiras camadas, utilizando-os como foram aprendidos no grande conjunto de dados, e usa um algoritmo de otimização para atualizar apenas W^5 e b^5. Esta abordagem é frequentemente útil quando você tem um conjunto de treinamento muito pequeno, pois permite que você se beneficie das características genéricas aprendidas com o grande conjunto de dados.\n",
    "\n",
    "2. **Opção 2**: Treinar todos os parâmetros da rede. Nesse caso, você inicializa as primeiras camadas com os parâmetros aprendidos anteriormente, mas permite que eles se ajustem durante o treinamento junto com os parâmetros da nova camada de saída. Esta opção pode ser mais eficaz se você tiver um conjunto de treinamento moderadamente grande, permitindo que a rede se ajuste mais especificamente aos dados dos dígitos escritos à mão.\n",
    "\n",
    "Essas etapas são conhecidas como pré-treinamento supervisionado (treinamento inicial no grande conjunto de dados) e ajuste fino (fine-tuning), onde você ajusta a rede para se especializar na tarefa específica de reconhecimento de dígitos.\n",
    "\n",
    "Além disso, uma vantagem significativa da transferência de aprendizado é que você pode não precisar realizar o pré-treinamento supervisionado por conta própria. Muitas redes neurais já são pré-treinadas e disponibilizadas gratuitamente por pesquisadores, permitindo que você simplesmente baixe uma dessas redes, substitua a camada de saída e faça o ajuste fino conforme necessário. Isso pode economizar um tempo considerável e esforço, além de proporcionar um ponto de partida robusto para o reconhecimento eficaz dos dígitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizado Hierárquico de Características\n",
    "\n",
    "Quando uma rede neural é treinada em um conjunto de dados que inclui imagens diversas—como gatos, cachorros, carros e pessoas—, as camadas iniciais da rede geralmente aprendem a reconhecer características básicas e de baixo nível. Estas incluem bordas e texturas, que são componentes fundamentais de qualquer imagem:\n",
    "\n",
    "1. **Primeiras Camadas**: Essas camadas iniciais aprendem a detectar padrões simples, como bordas e orientações dentro de uma imagem. Isso ocorre porque, independentemente da complexidade da imagem, as informações geométricas e texturais básicas formam os elementos visuais fundamentais.\n",
    "\n",
    "2. **Camadas Intermediárias**: À medida que avançamos na rede, as camadas começam a agrupar esses elementos básicos em padrões mais complexos, como cantos e contornos. Esses são um pouco mais abstratos do que os valores de pixels brutos, mas ainda genéricos o suficiente para serem aplicáveis em uma ampla gama de imagens.\n",
    "\n",
    "3. **Camadas Mais Profundas**: Mais adiante na rede, as camadas podem começar a identificar formas ou componentes específicos que podem estar mais associados às categorias específicas do conjunto de dados de treinamento (como partes de carros ou características de animais). Essas características são mais especializadas em comparação com os padrões genéricos reconhecidos pelas camadas anteriores.\n",
    "\n",
    "### Aplicação em Novos Domínios\n",
    "\n",
    "Ao aplicar a transferência de aprendizado, a ideia geral é pegar uma rede treinada em uma tarefa e adaptá-la para uma nova tarefa, retraindo principalmente a camada de saída, enquanto mantém as camadas anteriores fixas (ou ajustando-as levemente). Isso funciona porque as características visuais fundamentais (como bordas e texturas) que a rede aprendeu com a tarefa original também são úteis para novas tarefas relacionadas. Por exemplo:\n",
    "\n",
    "- **Reconhecimento de Dígitos Escritos à Mão**: Embora a rede original tenha sido treinada em imagens de animais e objetos, os padrões visuais básicos que aprendeu (bordas, texturas, etc.) também são cruciais para reconhecer dígitos escritos à mão. Ao transferir essas características aprendidas, a rede não precisa aprender do zero como interpretar informações visuais básicas, o que pode reduzir significativamente a quantidade de novos dados necessários.\n",
    "\n",
    "### Consistência do Tipo de Entrada\n",
    "\n",
    "Um aspecto crítico para o sucesso da transferência de aprendizado é a consistência no tipo de dados usados ​​para as fases de pré-treinamento e ajuste fino. Por exemplo, uma rede pré-treinada em imagens deve ser ajustada em tipos semelhantes de imagens. Aplicar um modelo treinado em imagens a dados de áudio geralmente não seria eficaz porque as características relevantes para imagens (por exemplo, bordas) não são aplicáveis a sinais de áudio, que dependem de padrões de frequência e amplitude ao longo do tempo.\n",
    "\n",
    "### Implementação Prática\n",
    "\n",
    "Na prática, a transferência de aprendizado pode economizar recursos significativos e tempo de desenvolvimento. Modelos pré-treinados em grandes conjuntos de dados diversos (como ImageNet para imagens ou BERT para texto) já aprenderam uma representação robusta de seus respectivos domínios. Ao ajustar esses modelos em um conjunto de dados menor e específico para a tarefa, você pode alcançar alto desempenho sem a necessidade de extensa coleta de dados e treinamento desde o início."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ciclo completo de um projeto de aprendizado de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenvolver um sistema de aprendizado de máquina vai além do simples treinamento de um modelo. Envolve um ciclo completo que deve ser cuidadosamente planejado e executado. Vamos explorar esse ciclo completo usando o exemplo de um projeto de reconhecimento de fala.\n",
    "\n",
    "### Definição do Escopo do Projeto\n",
    "\n",
    "O primeiro passo é definir o escopo do projeto, determinando exatamente o que se deseja realizar. Por exemplo, pode-se decidir desenvolver um sistema de reconhecimento de fala para busca por voz em dispositivos móveis, substituindo a necessidade de digitação por comandos de voz.\n",
    "\n",
    "### Coleta de Dados\n",
    "\n",
    "Após definir o escopo, o próximo passo é coletar os dados necessários para treinar o sistema. Isso inclui obter gravações de áudio e suas respectivas transcrições. A qualidade e a relevância dos dados coletados são fundamentais para a eficácia do modelo.\n",
    "\n",
    "### Treinamento e Análise de Erro\n",
    "\n",
    "Com os dados em mãos, inicia-se o treinamento do modelo de reconhecimento de fala. Durante esse processo, é comum realizar análises de erro e de viés-variância para identificar pontos onde o modelo pode estar falhando. Por exemplo, pode-se descobrir que o modelo tem desempenho insuficiente em situações com ruído de fundo de um carro. Isso pode levar à coleta de mais dados nesse contexto específico ou à aplicação de técnicas como augmentação de dados para simular condições similares e melhorar o desempenho do modelo.\n",
    "\n",
    "### Implantação e Monitoramento\n",
    "\n",
    "Uma vez que o modelo atinge um desempenho satisfatório, ele pode ser implantado em um ambiente de produção. Isso significa torná-lo acessível para os usuários finais. A implantação eficaz requer a configuração de um servidor de inferência, que processará os dados de entrada (como clips de áudio) e aplicará o modelo para fazer previsões (como transcrições de texto).\n",
    "\n",
    "### Engenharia de Software e Escalabilidade\n",
    "\n",
    "Dependendo da escala do aplicativo, a engenharia de software pode variar significativamente. Um projeto pode necessitar desde simples ajustes em um laptop até o desenvolvimento de sistemas complexos que exigem recursos consideráveis de um data center para servir milhões de usuários. Além disso, é essencial implementar mecanismos de registro de dados e monitoramento para garantir que o sistema continue funcionando corretamente e para identificar quando os dados ou o ambiente estão mudando de maneira que possa afetar a precisão do modelo.\n",
    "\n",
    "### Manutenção Contínua e MLOps\n",
    "\n",
    "Após a implantação, é crucial manter o sistema monitorado e atualizado. Mudanças no ambiente, como o surgimento de novos termos populares não presentes nos dados de treinamento, podem reduzir a precisão do modelo. A prática de MLOps (Operações de Aprendizado de Máquina) envolve métodos sistemáticos para construir, implantar e manter sistemas de aprendizado de máquina, garantindo que eles sejam confiáveis, escaláveis e que mantenham um bom desempenho ao longo do tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Justiça, preconceito e ética"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ética na inteligência artificial e no aprendizado de máquina é uma preocupação crescente, especialmente à medida que essas tecnologias começam a afetar bilhões de pessoas globalmente. Desenvolver sistemas de aprendizado de máquina que impactam a vida das pessoas requer uma abordagem consciente e responsável para garantir que sejam justos e livres de vieses.\n",
    "\n",
    "### Problemas de Viés e Justiça\n",
    "\n",
    "Existem vários exemplos na história do aprendizado de máquina em que sistemas, amplamente divulgados, acabaram demonstrando níveis inaceitáveis de viés. Por exemplo, ferramentas de contratação que discriminaram contra mulheres ou sistemas de reconhecimento facial que associaram erroneamente indivíduos de pele escura a fotos criminais mais frequentemente do que indivíduos de pele clara. Esses são exemplos claros de falhas que devem ser evitadas desde o início do desenvolvimento de qualquer sistema.\n",
    "\n",
    "Além disso, algoritmos têm sido usados para aprovar empréstimos bancários de maneira enviesada, discriminando subgrupos específicos, ou mesmo para reforçar estereótipos negativos, o que pode desencorajar indivíduos de certos grupos demográficos a seguir carreiras ou oportunidades.\n",
    "\n",
    "### Uso Negativo e Ética\n",
    "\n",
    "A tecnologia de \"deepfake\", por exemplo, mostra como a IA pode ser usada para criar conteúdos falsos e potencialmente danosos se não houver transparência e consentimento. Além disso, vimos casos em que redes sociais amplificaram discursos tóxicos e incendiários por otimizarem o engajamento do usuário sem considerar as consequências éticas.\n",
    "\n",
    "### Construindo Sistemas Éticos\n",
    "\n",
    "Para mitigar esses problemas, é fundamental formar equipes diversificadas que possam antecipar e identificar possíveis problemas éticos. Equipes com diversidade de gênero, etnia, cultura, entre outros, são mais capazes de prever e corrigir problemas antes que eles causem danos ao serem implantados. Além disso, é útil realizar pesquisas bibliográficas sobre padrões ou diretrizes éticas específicas para a indústria em questão.\n",
    "\n",
    "### Auditoria e Planos de Mitigação\n",
    "\n",
    "Antes de implementar um sistema em produção, é crucial auditar e testar o sistema em diversas dimensões para garantir que não esteja enviesado contra subgrupos específicos. Desenvolver um plano de mitigação, como voltar a um sistema anterior que se sabe ser justo, é uma prática recomendada. Monitorar continuamente o sistema após a implantação permite identificar e resolver rapidamente qualquer dano emergente.\n",
    "\n",
    "### Importância da Ética na IA\n",
    "\n",
    "A ética é um campo complexo que tem sido estudado por milhares de anos e, infelizmente, não existe uma lista simples de verificações para garantir práticas éticas. No entanto, uma abordagem informada, a inclusão de verificações e balanços e a disposição para abordar e resolver problemas de viés e injustiça são essenciais para criar tecnologias que melhorem, e não prejudiquem, a sociedade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de erro para conjuntos de dados distorcidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao trabalhar com aplicações de aprendizado de máquina onde a proporção entre exemplos positivos e negativos é muito desequilibrada, métricas tradicionais de erro, como a precisão, podem não ser adequadas. Isso se deve ao fato de que em cenários com desequilíbrio significativo de classes, um classificador pode apresentar alta precisão simplesmente ao prever sempre a classe majoritária, sem efetivamente identificar os casos raros, que são críticos para a aplicação.\n",
    "\n",
    "### Exemplo de Detecção de Doenças Raras\n",
    "\n",
    "Considere o caso de um classificador binário projetado para detectar uma doença rara em pacientes com base em testes laboratoriais. Se a doença é muito rara, digamos que afete apenas 0,5% da população, um modelo que sempre prediz que nenhum paciente tem a doença (`y = 0`) alcançará uma precisão de 99,5%. Isso pode parecer eficiente à primeira vista, mas essa abordagem falha completamente em identificar os pacientes que realmente têm a doença.\n",
    "\n",
    "### O Problema com a Métrica de Precisão\n",
    "\n",
    "A precisão por si só não é uma métrica confiável nesse cenário porque um modelo que simplesmente prevê a classe mais frequente pode ter uma taxa de erro muito baixa, mas é inútil do ponto de vista prático. O modelo falha em cumprir seu propósito principal: identificar corretamente os casos da doença rara.\n",
    "\n",
    "### Métricas Alternativas\n",
    "\n",
    "Para lidar com conjuntos de dados desequilibrados, especialmente em tarefas críticas como a detecção de doenças, é essencial utilizar métricas que possam avaliar adequadamente a capacidade do modelo de detectar a classe minoritária. Algumas dessas métricas incluem:\n",
    "\n",
    "1. **Precisão e Revocação (Recall)**: \n",
    "   - **Precisão** avalia a proporção de identificações positivas que são corretas.\n",
    "   - **Revocação** mede a capacidade do modelo de identificar todos os casos relevantes da classe minoritária.\n",
    "\n",
    "2. **Pontuação F1**: É a média harmônica entre precisão e revocação, fornecendo um balanço entre as duas métricas. É particularmente útil quando ambos os tipos de erros (falsos positivos e falsos negativos) têm consequências significativas.\n",
    "\n",
    "3. **AUC-ROC**: A Área Sob a Curva da Característica de Operação do Receptor (ROC) avalia a capacidade do modelo de discriminar entre as classes em todos os limiares de classificação. Essa métrica é valiosa porque leva em consideração tanto a taxa de verdadeiros positivos quanto a de falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão e Métricas de Desempenho\n",
    "\n",
    "Para uma avaliação eficaz, usamos uma matriz de confusão, uma ferramenta que ajuda a visualizar o desempenho de um algoritmo de classificação. A matriz de confusão é uma tabela 2x2 que organiza as previsões do modelo em quatro categorias:\n",
    "\n",
    "- **Verdadeiros Positivos (VP)**: O modelo previu corretamente a presença da doença.\n",
    "- **Verdadeiros Negativos (VN)**: O modelo previu corretamente a ausência da doença.\n",
    "- **Falsos Positivos (FP)**: O modelo previu incorretamente a presença da doença.\n",
    "- **Falsos Negativos (FN)**: O modelo previu incorretamente a ausência da doença, falhando em detectar a doença quando realmente está presente.\n",
    "\n",
    "### Precisão e Revocação\n",
    "\n",
    "A partir da matriz de confusão, derivamos duas métricas críticas:\n",
    "\n",
    "1. **Precisão**: Esta métrica indica a proporção de diagnósticos positivos que foram corretos. É calculada como:\n",
    "   \n",
    "   $$\n",
    "   \\text{Precisão} = \\frac{VP}{VP + FP}\n",
    "   $$\n",
    "\n",
    "   Uma precisão de 75% significa que, dos casos identificados pelo modelo como positivos, 75% eram corretamente diagnosticados.\n",
    "\n",
    "2. **Revocação (Recall)**: Esta métrica mede a capacidade do modelo de identificar todos os casos reais da doença. É calculada como:\n",
    "\n",
    "   $$\n",
    "   \\text{Revocação} = \\frac{VP}{VP + FN}\n",
    "   $$\n",
    "\n",
    "   Uma revocação de 60% indica que o modelo conseguiu identificar 60% de todos os casos reais da doença.\n",
    "\n",
    "### Aplicação Prática\n",
    "\n",
    "A combinação de precisão e revocação oferece uma visão mais completa sobre o desempenho de um modelo em cenários de desequilíbrio de classe. Por exemplo, um modelo que prediz que todos os pacientes não têm a doença terá uma revocação de 0%, o que é inaceitável em um contexto médico onde identificar cada caso de doença é crucial.\n",
    "\n",
    "Além disso, calcular essas métricas ajuda a detectar se um modelo está simplesmente prevendo a classe majoritária sem aprender a identificar corretamente a condição rara. Um modelo com revocação zero é um indicativo claro de que ele não está servindo ao seu propósito prático, independentemente de sua precisão global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tradeoff precisão e recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendendo Precisão e Revocação\n",
    "\n",
    "- **Precisão**: Esta métrica indica quão confiáveis são as previsões positivas do modelo. Uma alta precisão significa que quando o modelo prevê a presença da doença, essa previsão é correta na maioria das vezes. A precisão é calculada pela razão entre os verdadeiros positivos e todos os casos classificados como positivos pelo modelo.\n",
    "  \n",
    "- **Revocação**: Refere-se à capacidade do modelo de identificar todos os casos reais da doença. Uma alta revocação significa que o modelo é capaz de detectar a maioria dos pacientes que realmente têm a doença. A revocação é determinada pela proporção de verdadeiros positivos em relação ao total de casos reais da doença.\n",
    "\n",
    "### O Compromisso entre Precisão e Revocação\n",
    "\n",
    "Na prática, frequentemente existe um trade-off entre precisão e revocação. Isso ocorre porque ajustar o modelo para maximizar uma das métricas geralmente resulta em uma redução da outra. Este compromisso é manipulado ajustando-se o limiar de classificação do modelo:\n",
    "\n",
    "- **Aumentar o Limiar**: Se o limiar for aumentado, por exemplo, para 0.7 ou 0.9, o modelo só classifica um caso como positivo se a probabilidade prevista de doença for muito alta. Isso aumenta a precisão, pois reduz as chances de falsos positivos, mas pode diminuir a revocação, pois casos reais da doença com menor probabilidade prevista podem ser negligenciados.\n",
    "\n",
    "- **Reduzir o Limiar**: Diminuir o limiar para, por exemplo, 0.3, significa que o modelo classifica um caso como positivo com uma menor certeza da presença da doença. Isso pode reduzir a precisão devido ao aumento de falsos positivos, mas aumenta a revocação, melhorando a capacidade do modelo de identificar pacientes com a doença.\n",
    "\n",
    "### Escolhendo o Limiar Adequado\n",
    "\n",
    "A escolha do limiar ideal depende das consequências específicas de falsos positivos e falsos negativos no contexto da aplicação:\n",
    "\n",
    "- **Consequências dos Falsos Positivos**: Se os tratamentos resultantes de diagnósticos falsos são invasivos ou caros, um limiar mais alto pode ser preferível para garantir alta precisão.\n",
    "  \n",
    "- **Consequências dos Falsos Negativos**: Se não tratar a doença tem consequências graves, pode ser melhor errar pelo excesso de cautela, adotando um limiar mais baixo para maximizar a revocação.\n",
    "\n",
    "Ajustar esse limiar é uma decisão estratégica que deve ser baseada em uma compreensão detalhada do problema de saúde, dos custos associados a cada tipo de erro e das expectativas dos pacientes e profissionais de saúde envolvidos.\n",
    "\n",
    "### Visualização e Ajuste\n",
    "\n",
    "Plotar uma curva de precisão versus revocação para diferentes valores de limiar pode ajudar a visualizar e escolher o ponto de equilíbrio ideal. Esse ponto será onde os benefícios de alta precisão e alta revocação são otimizados de acordo com os objetivos específicos e as restrições do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O F1 score é uma métrica crucial quando se trabalha com conjuntos de dados onde a precisão e a revocação são importantes e existe um trade-off entre essas duas medidas. Ele é particularmente útil para ajudar a decidir entre diferentes modelos quando não há um claro que se destaque tanto em precisão quanto em revocação.\n",
    "\n",
    "### Como o F1 Score Funciona\n",
    "\n",
    "O F1 score combina precisão e revocação em uma única métrica que busca um equilíbrio entre elas, dando mais ênfase ao menor dos dois valores. Isso é particularmente importante porque um modelo com alta precisão mas baixa revocação, ou vice-versa, pode não ser muito útil dependendo do contexto da aplicação. Por exemplo, em um contexto médico, um modelo que identifica corretamente as doenças (alta precisão) mas falha em identificar muitos casos (baixa revocação) pode ser perigoso.\n",
    "\n",
    "### Cálculo do F1 Score\n",
    "\n",
    "O F1 score é definido como a média harmônica da precisão e da revocação. Sua fórmula é:\n",
    "\n",
    "$$ F1 = 2 \\times \\frac{\\text{Precisão} \\times \\text{Revocação}}{\\text{Precisão} + \\text{Revocação}} $$\n",
    "\n",
    "Essa fórmula assegura que o F1 score só será alto se ambos, precisão e revocação, forem altos. Ele penaliza severamente os modelos que têm um desempenho desequilibrado em termos de precisão e revocação.\n",
    "\n",
    "### Por Que Não Usar a Média Simples\n",
    "\n",
    "A média simples da precisão e revocação pode ser enganosa porque não reflete adequadamente o impacto de ter um valor muito baixo em uma das medidas. Um modelo pode ter uma revocação perfeita (por exemplo, identificando todos os casos positivos corretamente) mas uma precisão muito baixa (muitos falsos positivos), resultando em um número médio que parece aceitável mas que na realidade representa um modelo pouco prático e possivelmente perigoso.\n",
    "\n",
    "### Exemplo de Aplicação do F1 Score\n",
    "\n",
    "Considerando três algoritmos com diferentes valores de precisão e revocação, o F1 score ajuda a identificar qual algoritmo realmente oferece o melhor equilíbrio:\n",
    "\n",
    "- Algoritmo 1: Precisão = 0.6, Revocação = 0.4\n",
    "- Algoritmo 2: Precisão = 0.7, Revocação = 0.1\n",
    "- Algoritmo 3: Precisão = 0.2, Revocação = 0.9\n",
    "\n",
    "Calculando o F1 para cada um, verificamos que o Algoritmo 1 tem um F1 score de 0.444, o Algoritmo 2 tem 0.175, e o Algoritmo 3 tem 0.0392. Apesar dos extremos em precisão ou revocação nos Algoritmos 2 e 3, o Algoritmo 1, que tem um equilíbrio mais razoável, acaba sendo mais adequado segundo o F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
